{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf Word embedding in sklearn: Method 1: TfidfVectorizer()\n",
    "modified from https://www.cnblogs.com/pinard/p/6693230.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 14)\t0.404624139215726\n",
      "  (0, 4)\t0.404624139215726\n",
      "  (0, 16)\t0.6380206378428825\n",
      "  (0, 3)\t0.31901031892144127\n",
      "  (0, 17)\t0.404624139215726\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 15)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (2, 7)\t0.5\n",
      "  (2, 12)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (3, 16)\t0.2811316284405006\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 19)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n",
      "{'they': 14, 'come': 4, 'to': 16, 'china': 3, 'travel': 17, 'this': 15, 'is': 6, 'car': 2, 'polupar': 9, 'in': 5, 'love': 7, 'tea': 12, 'and': 0, 'apple': 1, 'the': 13, 'work': 18, 'write': 19, 'some': 11, 'papers': 8, 'science': 10}\n",
      "20\n",
      "[[0.         0.         0.         0.31901032 0.40462414 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.40462414 0.         0.63802064 0.40462414\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.4533864  0.35745504 0.         0.35745504\n",
      "  0.35745504 0.         0.         0.4533864  0.         0.\n",
      "  0.         0.         0.         0.4533864  0.         0.\n",
      "  0.         0.        ]\n",
      " [0.5        0.5        0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.28113163\n",
      "  0.28113163 0.         0.35657982 0.         0.35657982 0.35657982\n",
      "  0.         0.35657982 0.         0.         0.28113163 0.\n",
      "  0.35657982 0.35657982]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf2 = TfidfVectorizer()\n",
    "corpus=[\"They come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "re = tfidf2.fit_transform(corpus)\n",
    "print (re) # output tfidf values for each word\n",
    "print (tfidf2.vocabulary_) #output index and words\n",
    "print (len(tfidf2.vocabulary_.keys())) ##output the number of words\n",
    "print (re.todense()) #output matrix for the corpus/documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 16)\t0.4424621378947393\n",
      "  (0, 15)\t0.697684463383976\n",
      "  (0, 4)\t0.4424621378947393\n",
      "  (0, 3)\t0.348842231691988\n",
      "  (1, 14)\t0.45338639737285463\n",
      "  (1, 9)\t0.45338639737285463\n",
      "  (1, 6)\t0.3574550433419527\n",
      "  (1, 5)\t0.3574550433419527\n",
      "  (1, 3)\t0.3574550433419527\n",
      "  (1, 2)\t0.45338639737285463\n",
      "  (2, 12)\t0.5\n",
      "  (2, 7)\t0.5\n",
      "  (2, 1)\t0.5\n",
      "  (2, 0)\t0.5\n",
      "  (3, 18)\t0.3565798233381452\n",
      "  (3, 17)\t0.3565798233381452\n",
      "  (3, 15)\t0.2811316284405006\n",
      "  (3, 13)\t0.3565798233381452\n",
      "  (3, 11)\t0.3565798233381452\n",
      "  (3, 10)\t0.3565798233381452\n",
      "  (3, 8)\t0.3565798233381452\n",
      "  (3, 6)\t0.2811316284405006\n",
      "  (3, 5)\t0.2811316284405006\n",
      "19\n",
      "['and', 'apple', 'car', 'china', 'come', 'in', 'is', 'love', 'papers', 'polupar', 'science', 'some', 'tea', 'the', 'this', 'to', 'travel', 'work', 'write']\n",
      "[[0.         0.         0.         0.34884223 0.44246214 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.69768446 0.44246214 0.\n",
      "  0.        ]\n",
      " [0.         0.         0.4533864  0.35745504 0.         0.35745504\n",
      "  0.35745504 0.         0.         0.4533864  0.         0.\n",
      "  0.         0.         0.4533864  0.         0.         0.\n",
      "  0.        ]\n",
      " [0.5        0.5        0.         0.         0.         0.\n",
      "  0.         0.5        0.         0.         0.         0.\n",
      "  0.5        0.         0.         0.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         0.         0.28113163\n",
      "  0.28113163 0.         0.35657982 0.         0.35657982 0.35657982\n",
      "  0.         0.35657982 0.         0.28113163 0.         0.35657982\n",
      "  0.35657982]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer  \n",
    "from sklearn.feature_extraction.text import CountVectorizer  \n",
    "corpus=[\"I come to China to travel\", \n",
    "    \"This is a car polupar in China\",          \n",
    "    \"I love tea and Apple \",   \n",
    "    \"The work is to write some papers in science\"] \n",
    "vectorizer=CountVectorizer()\n",
    "transformer = TfidfTransformer()\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))  \n",
    "print (tfidf)  #output tfidf values for words\n",
    "print (len(tfidf.toarray()[0])) #output the number of words\n",
    "print (vectorizer.get_feature_names()) #output index and words\n",
    "print (tfidf.toarray()) #output matrix for the corpus/documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some important paramerters\n",
    "Please note the difference of words return (20 Vs 19) when change from They to I is because the token_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "token_pattern : string\n",
    "    Regular expression denoting what constitutes a \"token\", only used\n",
    "    if ``analyzer == 'word'``. The default regexp selects tokens of 2\n",
    "    or more alphanumeric characters (punctuation is completely ignored\n",
    "    and always treated as a token separator).\n",
    "\n",
    "max_df : float in range [0.0, 1.0] or int, default=1.0\n",
    "    When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly higher than the given threshold (corpus-specific\n",
    "    stop words).\n",
    "    If float, the parameter represents a proportion of documents, integer\n",
    "    absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "ignore words that show up in all documents (100%).\n",
    "\n",
    "min_df : float in range [0.0, 1.0] or int, default=1\n",
    "    When building the vocabulary ignore terms that have a document\n",
    "    frequency strictly lower than the given threshold. This value is also\n",
    "    called cut-off in the literature.\n",
    "    If float, the parameter represents a proportion of documents, integer\n",
    "    absolute counts.\n",
    "    This parameter is ignored if vocabulary is not None.\n",
    "    \n",
    "ignore words that have freqnecy lower than 1."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
