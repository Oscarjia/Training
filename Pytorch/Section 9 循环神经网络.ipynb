{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 73序列表示方法\n",
    "https://www.udemy.com/course/deeplearning-pytorch/learn/lecture/14400062#announcements <br>\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials/blob/master/lesson46-时间序列表示/46.pdf"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[单词的个数，word的维度]\n",
    "[sample size, dimension of the features]\n",
    "\n",
    "for exampl : [5, 300] 用300维表示五个单词的句子\n",
    "英文常用的是2-4万多个词\n",
    "中文3500 to 5000多个\n",
    "\n",
    "NLP: 两种input 形式： batch： 一次train多个instances\n",
    "[word num, batch number, word vec维度] \n",
    "[batch number, word num, word vec维度]\n",
    "\n",
    "对于CNN：[batch size, channel, height, width] \n",
    "可以用查表的方式来做embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.nn.Embedding\n",
    "##create word embeddings based on nthe lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0])\n",
      "tensor([[-0.9856, -0.0927, -1.0295,  1.1818,  0.2779]],\n",
      "       grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "word_to_ix ={ \"hello\":0, \"world\": 1}\n",
    "lookup_tensor = torch.tensor([word_to_ix['hello']], dtype=torch.long)\n",
    "print (lookup_tensor)\n",
    "embeds = nn.Embedding(2,5)\n",
    "#2 words in vocab, 5 dimensionnal embeddings\n",
    "hello_embed = embeds(lookup_tensor)\n",
    "print (hello_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://zixia_wang:****@artifacts.geo.apple.com/artifactory/api/pypi/pypi-repos/simple, https://pypi.apple.com/simple\n",
      "Collecting torchnlp\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/torchnlp/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/torchnlp/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/torchnlp/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/torchnlp/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/torchnlp/\u001b[0m\n",
      "  Could not fetch URL https://zixia_wang:****@artifacts.geo.apple.com/artifactory/api/pypi/pypi-repos/simple/torchnlp/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='artifacts.geo.apple.com', port=443): Max retries exceeded with url: /artifactory/api/pypi/pypi-repos/simple/torchnlp/ (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)) - skipping\n",
      "  Using cached https://pypi.apple.com/packages/packages/58/92/8d583328e33268466c29fe45ac0652c07633dcd9daea727457ff4bacb378/torchnlp-0.0.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: torchtext==0.4.0 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (0.4.0)\n",
      "Requirement already satisfied: revtok in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (0.0.3)\n",
      "Requirement already satisfied: pytorch-crf==0.7.0 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (0.7.0)\n",
      "Requirement already satisfied: nltk in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (3.3)\n",
      "Requirement already satisfied: jieba in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (0.39)\n",
      "Requirement already satisfied: tqdm==4.28.1 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (4.28.1)\n",
      "Requirement already satisfied: scikit-learn==0.20.2 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (0.20.2)\n",
      "Collecting regex (from torchnlp)\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/regex/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/regex/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/regex/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/regex/\u001b[0m\n",
      "\u001b[33m  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)': /artifactory/api/pypi/pypi-repos/simple/regex/\u001b[0m\n",
      "  Could not fetch URL https://zixia_wang:****@artifacts.geo.apple.com/artifactory/api/pypi/pypi-repos/simple/regex/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='artifacts.geo.apple.com', port=443): Max retries exceeded with url: /artifactory/api/pypi/pypi-repos/simple/regex/ (Caused by SSLError(SSLError(\"bad handshake: Error([('SSL routines', 'tls_process_server_certificate', 'certificate verify failed')],)\",),)) - skipping\n",
      "  Using cached https://pypi.apple.com/packages/packages/fc/1d/13cc7d174cd2d05808abac3f5fb37433e30c4cd93b152d2a9c09c926d7e8/regex-2019.11.1.tar.gz\n",
      "Requirement already satisfied: torch==1.0.0 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchnlp) (1.0.0)\n",
      "Requirement already satisfied: six in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchtext==0.4.0->torchnlp) (1.11.0)\n",
      "Requirement already satisfied: numpy in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchtext==0.4.0->torchnlp) (1.16.2)\n",
      "Requirement already satisfied: requests in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from torchtext==0.4.0->torchnlp) (2.21.0)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from scikit-learn==0.20.2->torchnlp) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->torchnlp) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->torchnlp) (2.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->torchnlp) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/zixiawang/anaconda2/envs/py36/lib/python3.6/site-packages (from requests->torchtext==0.4.0->torchnlp) (3.0.4)\n",
      "Building wheels for collected packages: regex\n",
      "  Building wheel for regex (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /Users/zixiawang/anaconda2/envs/py36/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-wheel-co4e3_0q --python-tag cp36\n",
      "       cwd: /private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/\n",
      "  Complete output (79 lines):\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6\n",
      "  creating build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "  copying regex_3/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "  copying regex_3/regex.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "  copying regex_3/_regex_core.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "  copying regex_3/test_regex.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "  running build_ext\n",
      "  building 'regex._regex' extension\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6\n",
      "  creating build/temp.macosx-10.7-x86_64-3.6/regex_3\n",
      "  gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/zixiawang/anaconda2/envs/py36/include -arch x86_64 -I/Users/zixiawang/anaconda2/envs/py36/include -arch x86_64 -I/Users/zixiawang/anaconda2/envs/py36/include/python3.6m -c regex_3/_regex.c -o build/temp.macosx-10.7-x86_64-3.6/regex_3/_regex.o\n",
      "  In file included from regex_3/_regex.c:48:\n",
      "  In file included from /Users/zixiawang/anaconda2/envs/py36/include/python3.6m/Python.h:34:\n",
      "  In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/stdlib.h:66:\n",
      "  In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/wait.h:110:\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:196:2: error: unknown type name 'uint8_t'\n",
      "          uint8_t  ri_uuid[16];\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:197:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_user_time;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:198:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_system_time;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:199:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_pkg_idle_wkups;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:200:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_interrupt_wkups;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:201:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_pageins;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:202:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_wired_size;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:203:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_resident_size;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:204:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_phys_footprint;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:205:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_proc_start_abstime;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:206:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_proc_exit_abstime;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:210:2: error: unknown type name 'uint8_t'\n",
      "          uint8_t  ri_uuid[16];\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:211:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_user_time;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:212:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_system_time;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:213:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_pkg_idle_wkups;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:214:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_interrupt_wkups;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:215:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_pageins;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:216:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_wired_size;\n",
      "          ^\n",
      "  /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:217:2: error: unknown type name 'uint64_t'\n",
      "          uint64_t ri_resident_size;\n",
      "          ^\n",
      "  fatal error: too many errors emitted, stopping now [-ferror-limit=]\n",
      "  20 errors generated.\n",
      "  error: command 'gcc' failed with exit status 1\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for regex\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for regex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build regex\n",
      "Installing collected packages: regex, torchnlp\n",
      "  Running setup.py install for regex ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /Users/zixiawang/anaconda2/envs/py36/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-record-gytagrf1/install-record.txt --single-version-externally-managed --compile\n",
      "         cwd: /private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/\n",
      "    Complete output (79 lines):\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6\n",
      "    creating build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "    copying regex_3/__init__.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "    copying regex_3/regex.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "    copying regex_3/_regex_core.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "    copying regex_3/test_regex.py -> build/lib.macosx-10.7-x86_64-3.6/regex\n",
      "    running build_ext\n",
      "    building 'regex._regex' extension\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6\n",
      "    creating build/temp.macosx-10.7-x86_64-3.6/regex_3\n",
      "    gcc -Wno-unused-result -Wsign-compare -Wunreachable-code -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes -I/Users/zixiawang/anaconda2/envs/py36/include -arch x86_64 -I/Users/zixiawang/anaconda2/envs/py36/include -arch x86_64 -I/Users/zixiawang/anaconda2/envs/py36/include/python3.6m -c regex_3/_regex.c -o build/temp.macosx-10.7-x86_64-3.6/regex_3/_regex.o\n",
      "    In file included from regex_3/_regex.c:48:\n",
      "    In file included from /Users/zixiawang/anaconda2/envs/py36/include/python3.6m/Python.h:34:\n",
      "    In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/stdlib.h:66:\n",
      "    In file included from /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/wait.h:110:\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:196:2: error: unknown type name 'uint8_t'\n",
      "            uint8_t  ri_uuid[16];\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:197:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_user_time;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:198:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_system_time;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:199:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_pkg_idle_wkups;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:200:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_interrupt_wkups;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:201:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_pageins;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:202:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_wired_size;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:203:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_resident_size;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:204:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_phys_footprint;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:205:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_proc_start_abstime;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:206:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_proc_exit_abstime;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:210:2: error: unknown type name 'uint8_t'\n",
      "            uint8_t  ri_uuid[16];\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:211:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_user_time;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:212:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_system_time;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:213:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_pkg_idle_wkups;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:214:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_interrupt_wkups;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:215:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_pageins;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:216:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_wired_size;\n",
      "            ^\n",
      "    /Library/Developer/CommandLineTools/SDKs/MacOSX10.14.sdk/usr/include/sys/resource.h:217:2: error: unknown type name 'uint64_t'\n",
      "            uint64_t ri_resident_size;\n",
      "            ^\n",
      "    fatal error: too many errors emitted, stopping now [-ferror-limit=]\n",
      "    20 errors generated.\n",
      "    error: command 'gcc' failed with exit status 1\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /Users/zixiawang/anaconda2/envs/py36/bin/python -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-install-fn06d64q/regex/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /private/var/folders/cc/rpzkx16j4bg9cwh9pmkgzs2w0000gn/T/pip-record-gytagrf1/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install torchnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchnlp'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-230a70691cab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#也可以用现有的GLoVe 去做embedding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_to_vector\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGloVe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hello'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchnlp'"
     ]
    }
   ],
   "source": [
    "#也可以用现有的GLoVe 去做embedding\n",
    "## this need to download a 2Gb files \n",
    "from torchnlp.word_to_vector import GloVe\n",
    "vectors = GloVe()\n",
    "vectors['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN 原理\n",
    "https://www.udemy.com/course/deeplearning-pytorch/learn/lecture/14400064#announcements <br>\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials/blob/master/lesson47-RNN原理/47.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RNN weight sharing：把每一个词的线性写w 和b 共享，而不是每一个词都有自己的w和b, 这样子可以处理比较长的句子\n",
    "Consistent Memory：这样子可以做到语境贯穿。\n",
    "unfold model：至于最后用哪个h， 最后一个还是中间某一个，这个是可以根据具体情况记性调整的。 \n",
    "RNN里面的激活函数更多的用的是tanh [-1， 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.udemy.com/course/deeplearning-pytorch/learn/lecture/14400070#announcements"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "RNN 句子常见表达形式：\n",
    "X: [seq length, batch, feature length] 这个是input的句子\n",
    "seq: 一个句子有多少个词， batch 一次train 几个句子， word embedding的维度\n",
    "Xt:  [batch, feature len] 这个是t时刻的x（位置为t的词）\n",
    "\n",
    "Xt@Wxh + ht@Whh\n",
    "[batch size, feature size] @ transpose([hidden size, feture size]) + \n",
    "[batch size, hidden size] @ [hidden size, hidden size ]\n",
    "\n",
    "所以最初的memory 要初始化为[batch, hidden length] 每个obs都要有初始化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN 已经在时间上展开了，所以在空间上不可能象CNN 那么长，一般控制在2-10层左右 <br>\n",
    "可以用_parameters 来看一个rnn含有的所有参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.RNN()\n",
    "#batch_first: If ``True``, then the input and output tensors are provided as\n",
    "`(batch, seq, feature)`. Default: ``False``\n",
    "所以default 应该是： input** of shape `(seq_len, batch, input_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### nn.RNN 输入格式 (input_size, hidden_size, num_layers)\n",
    "### word dim 100, 10 memorty hidden "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['weight_ih_l0', 'weight_hh_l0', 'bias_ih_l0', 'bias_hh_l0'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn = nn.RNN(100, 10)\n",
    "rnn._parameters.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0', Parameter containing:\n",
       "              tensor([[-2.9390e-02,  2.7446e-01, -2.4776e-01,  1.9801e-02,  2.7945e-01,\n",
       "                        2.3322e-01, -1.5343e-01, -4.1531e-02, -7.2627e-03, -1.3104e-01,\n",
       "                        2.2595e-01,  1.1517e-01, -2.6512e-01,  2.8372e-01,  2.6041e-01,\n",
       "                       -1.9214e-01,  2.3136e-01,  2.6856e-01, -1.3836e-01,  1.3824e-01,\n",
       "                        1.8387e-01, -1.1189e-01,  2.3983e-02,  1.5303e-01, -3.0848e-01,\n",
       "                       -3.1340e-02,  6.2046e-02, -3.1200e-01,  2.9461e-01,  2.5162e-01,\n",
       "                       -7.7298e-02,  1.2799e-02,  5.8208e-02, -1.3360e-02, -1.9479e-01,\n",
       "                        1.0389e-01,  1.8404e-01,  8.3476e-02,  6.7512e-02, -2.1365e-01,\n",
       "                       -1.1164e-01, -1.1182e-01,  1.2860e-01,  2.8954e-01, -9.6933e-02,\n",
       "                        3.1448e-01,  3.1376e-01, -1.8210e-01,  1.3130e-01,  6.4263e-02,\n",
       "                        8.9464e-02,  2.0802e-01,  2.5987e-01, -1.5662e-01,  7.1649e-03,\n",
       "                        1.9935e-03,  4.8653e-02,  1.9445e-01,  1.4316e-01, -1.4321e-01,\n",
       "                       -2.7375e-01,  1.8412e-01,  7.3894e-02,  1.3834e-01, -1.8358e-01,\n",
       "                       -7.9931e-03,  9.2820e-02,  3.1253e-01, -2.5927e-01,  1.9488e-01,\n",
       "                        5.4714e-02,  1.2717e-01,  2.0582e-01, -1.7865e-01,  1.1608e-01,\n",
       "                       -3.1118e-01, -1.7565e-02, -1.6878e-01,  5.3514e-02,  2.3830e-01,\n",
       "                       -1.9132e-01,  1.8785e-02,  1.6364e-01,  1.0213e-01,  1.1287e-01,\n",
       "                       -6.5165e-02, -5.6066e-02,  6.0148e-02,  1.6153e-01, -1.2572e-01,\n",
       "                       -1.3137e-01,  2.6677e-01,  9.6280e-03, -2.0818e-01,  2.2144e-01,\n",
       "                       -1.8567e-01,  3.1493e-01, -2.2417e-01, -1.9461e-01,  3.0825e-01],\n",
       "                      [ 1.0884e-01, -4.8325e-02,  2.2902e-01,  2.6398e-01,  7.6584e-02,\n",
       "                       -7.7379e-02, -3.0068e-02, -3.0797e-02,  2.7130e-01, -4.0566e-02,\n",
       "                        1.1661e-01,  8.6096e-03, -4.3987e-02, -1.6328e-01, -1.8129e-01,\n",
       "                       -5.5470e-02, -1.4201e-01, -1.2054e-01, -4.5025e-02, -2.9159e-01,\n",
       "                       -1.9367e-02,  1.8866e-01,  1.2441e-01, -5.0945e-02, -1.7333e-01,\n",
       "                        2.2142e-01,  2.9405e-02,  2.7240e-01,  8.1001e-03,  7.4574e-02,\n",
       "                        1.8647e-01,  2.3914e-01, -1.7807e-01,  7.9207e-02,  2.5104e-01,\n",
       "                       -2.6075e-01, -1.8950e-01, -2.1333e-01, -2.9971e-01,  1.5561e-01,\n",
       "                        1.0773e-01,  2.0986e-02, -1.5782e-01, -2.9979e-01,  9.8603e-02,\n",
       "                       -5.3719e-02, -3.5272e-02,  1.2885e-02,  1.9478e-01,  2.4101e-01,\n",
       "                        2.4392e-01, -2.0973e-01,  2.7351e-01,  1.2931e-01, -9.4641e-02,\n",
       "                       -3.3351e-02,  2.6327e-01, -3.0848e-01, -2.4604e-01, -2.7588e-01,\n",
       "                       -1.0972e-01,  2.0479e-01,  2.4127e-01,  1.0190e-01,  4.4642e-02,\n",
       "                        2.3757e-01, -1.2822e-01,  2.1453e-01, -2.7617e-01, -2.1696e-01,\n",
       "                       -6.3252e-02,  2.3656e-01,  2.0872e-02,  1.2144e-01, -4.6952e-02,\n",
       "                        9.6885e-02, -2.1879e-01, -1.7239e-02, -1.5259e-01, -1.6480e-01,\n",
       "                        1.8797e-01,  2.4776e-01,  2.2826e-01, -6.4030e-02, -4.2297e-02,\n",
       "                        2.0033e-01, -2.9003e-01, -2.4295e-01, -1.6620e-01,  4.6936e-02,\n",
       "                       -1.3583e-02, -3.0871e-01,  3.0665e-01, -9.4759e-02,  2.1198e-01,\n",
       "                        1.5085e-01,  1.8224e-01, -1.9676e-01,  1.2843e-01,  1.9018e-01],\n",
       "                      [-3.0340e-01, -2.1681e-01,  2.9352e-01,  6.4158e-02,  2.4282e-02,\n",
       "                       -3.1063e-01,  1.5259e-01, -2.2079e-01, -9.1776e-02, -2.3326e-01,\n",
       "                        7.5812e-02, -8.5380e-02,  1.1830e-01, -2.0579e-01,  9.6754e-02,\n",
       "                        2.2541e-01,  2.6130e-02,  4.0554e-02, -6.4931e-02,  1.5940e-01,\n",
       "                       -3.0799e-01,  4.7634e-02, -1.1350e-01,  2.6732e-01,  1.0610e-01,\n",
       "                       -2.7871e-01, -9.7107e-02,  2.5263e-01,  3.0770e-01, -2.7195e-01,\n",
       "                       -1.3615e-01, -2.2518e-01, -4.1690e-02, -1.7843e-01, -2.4045e-01,\n",
       "                       -1.6563e-01,  2.8274e-01, -2.5503e-01,  2.8345e-01, -2.3218e-01,\n",
       "                       -3.6321e-02, -3.0539e-01, -4.1131e-02,  2.6014e-01,  2.2871e-01,\n",
       "                        2.4360e-01,  1.6751e-01, -6.6711e-02, -8.4398e-02, -6.9839e-02,\n",
       "                       -1.2211e-01,  3.0916e-01,  1.5405e-01, -2.2618e-01, -3.1369e-01,\n",
       "                        6.4223e-02,  1.2158e-01, -2.5591e-01, -2.2983e-01, -2.0351e-01,\n",
       "                       -2.6283e-01, -1.8794e-01, -1.6906e-01,  1.2628e-01, -2.8722e-01,\n",
       "                       -1.0605e-01,  2.6338e-01, -2.6221e-01,  1.3577e-01,  2.4939e-01,\n",
       "                       -2.9193e-01,  2.2007e-01,  1.9730e-01,  2.3249e-01,  2.1203e-01,\n",
       "                       -2.0451e-01,  2.1709e-01,  1.6239e-02,  1.9715e-01,  1.4526e-01,\n",
       "                       -1.3902e-01,  1.4405e-01, -4.9490e-02,  3.5033e-02,  1.7375e-01,\n",
       "                       -3.2783e-02, -2.7303e-01, -2.2123e-01,  2.2891e-01, -4.7094e-03,\n",
       "                       -2.2303e-01, -2.9427e-01,  7.2711e-02,  6.5319e-02, -1.2059e-01,\n",
       "                        1.5724e-01, -2.2434e-01,  1.6219e-01,  1.0980e-01,  1.3323e-01],\n",
       "                      [ 1.7698e-01,  4.4248e-02, -6.6431e-02, -9.6498e-02,  7.4959e-02,\n",
       "                        3.6502e-02,  3.0386e-01, -7.9349e-02, -2.5985e-01,  2.8639e-01,\n",
       "                        8.0544e-02,  6.3237e-02,  1.1174e-01,  8.9704e-02, -3.6750e-02,\n",
       "                        9.1763e-02, -1.2334e-01,  1.0550e-01,  1.9989e-01,  1.1529e-01,\n",
       "                        2.8513e-01, -5.2146e-02,  4.5058e-02,  1.6664e-01, -2.6641e-01,\n",
       "                        6.5734e-02, -2.8921e-01,  1.1633e-01, -2.5306e-01, -2.8587e-02,\n",
       "                       -1.8485e-01,  9.8821e-02, -1.9768e-01,  9.5912e-02, -1.3314e-01,\n",
       "                        1.4359e-01,  9.7486e-02, -2.9714e-01,  1.3937e-01, -3.0348e-01,\n",
       "                        2.5638e-01, -1.7246e-01,  1.4791e-01,  2.3255e-01,  2.1550e-02,\n",
       "                        1.1736e-01, -1.2376e-01, -1.8595e-01,  1.9245e-01,  1.7488e-01,\n",
       "                       -7.2991e-02,  7.4698e-02, -6.1604e-02, -8.3497e-02,  7.7940e-02,\n",
       "                       -1.9627e-01,  1.8811e-03, -2.4111e-01, -2.3412e-01,  2.4604e-01,\n",
       "                       -6.5152e-02,  4.6758e-02, -1.8320e-01, -5.2812e-02, -1.1724e-01,\n",
       "                        3.0502e-01,  1.2888e-01,  5.4222e-02, -1.7802e-01,  1.0170e-01,\n",
       "                        1.4804e-01,  1.3487e-01, -2.2732e-03, -1.9551e-02,  1.3661e-01,\n",
       "                       -7.9047e-02,  2.1705e-01,  2.5142e-01, -1.0083e-01,  2.2948e-01,\n",
       "                       -1.3909e-01,  2.2987e-02, -2.0841e-01,  6.8195e-02,  2.9160e-01,\n",
       "                        6.3929e-02, -1.7083e-01, -1.5549e-01,  1.7800e-01,  4.5875e-02,\n",
       "                        2.1935e-01, -2.2841e-01,  6.3231e-02,  1.8568e-01,  1.8825e-01,\n",
       "                       -1.2357e-01, -1.8258e-01,  8.4596e-02, -6.0286e-03, -1.2419e-01],\n",
       "                      [-1.2398e-01, -2.5957e-01,  2.3358e-01,  8.0991e-02, -2.9112e-01,\n",
       "                        1.8659e-02, -2.5089e-01,  1.4118e-01,  3.1037e-01,  2.5797e-01,\n",
       "                       -1.1603e-01, -4.6566e-02,  1.9073e-01,  2.0625e-02,  6.2150e-03,\n",
       "                        9.4622e-02, -1.0359e-01,  3.6101e-02, -5.9785e-02, -1.4718e-01,\n",
       "                        2.4797e-01, -1.5787e-01,  1.1588e-02, -6.2790e-03, -2.3524e-01,\n",
       "                        2.7167e-01, -1.8458e-01, -1.0266e-01, -1.9974e-01,  2.5878e-01,\n",
       "                       -1.9542e-01,  1.1927e-01,  1.0150e-01, -1.3485e-01,  1.8488e-01,\n",
       "                        1.6768e-02,  2.8263e-01,  1.8670e-01,  7.5103e-02,  1.7800e-01,\n",
       "                        2.9603e-01, -1.4444e-01,  2.4948e-01,  2.7408e-01,  7.3261e-02,\n",
       "                       -2.4719e-01, -4.3879e-02, -1.7848e-01,  2.4216e-01, -1.4874e-01,\n",
       "                       -5.5201e-02,  1.6919e-01, -3.0971e-01,  2.1033e-01,  8.3897e-02,\n",
       "                        1.1566e-02,  2.0386e-01, -1.7173e-01, -2.4797e-02, -5.1801e-02,\n",
       "                        2.0917e-01,  3.3090e-02,  6.6607e-02, -3.0335e-01,  1.5534e-01,\n",
       "                       -1.5758e-01, -1.3893e-01, -1.5207e-01,  1.3109e-01,  1.6530e-01,\n",
       "                        1.4505e-01,  1.2061e-01, -2.9646e-01,  6.4396e-02,  1.3884e-01,\n",
       "                       -1.5673e-01, -1.8829e-01, -7.8773e-02,  5.0053e-02, -1.8767e-01,\n",
       "                        9.5008e-02, -1.4404e-01,  8.1462e-02,  1.6709e-01, -8.8269e-02,\n",
       "                       -1.9713e-01, -1.2051e-01, -1.6583e-01, -1.1474e-02,  2.8619e-01,\n",
       "                       -1.3934e-01,  2.8112e-02,  3.7915e-02, -4.2997e-03,  3.6611e-02,\n",
       "                       -1.2832e-01,  1.4296e-01, -1.8437e-01, -4.5582e-02,  1.2990e-01],\n",
       "                      [-9.4109e-02,  3.0288e-02, -2.1640e-01,  7.2459e-02,  7.3122e-02,\n",
       "                       -1.5203e-01, -1.5738e-02,  2.6440e-01, -3.0084e-02, -1.2095e-01,\n",
       "                        3.3992e-03,  8.1782e-02, -2.6408e-01, -2.7957e-01,  1.8326e-01,\n",
       "                        1.8912e-01,  6.3214e-02,  1.4040e-01,  2.8929e-02, -2.6551e-01,\n",
       "                       -1.7887e-01, -8.0340e-02, -2.0842e-01, -8.4761e-02, -3.0420e-02,\n",
       "                       -2.3369e-01,  2.6830e-01,  7.5429e-02,  7.7179e-02,  9.0497e-02,\n",
       "                       -2.0290e-01,  2.8849e-01, -8.0956e-02,  1.0733e-01,  5.8206e-02,\n",
       "                       -1.0673e-01, -4.3549e-02,  2.2596e-01,  8.7630e-02,  1.3161e-01,\n",
       "                        2.8332e-01, -5.4020e-02, -1.4554e-01,  2.5302e-01,  3.0301e-01,\n",
       "                       -7.3435e-02, -1.3913e-02,  1.4776e-04, -2.0808e-01, -6.0202e-02,\n",
       "                       -1.6393e-01, -1.5113e-01, -2.3523e-01, -2.6400e-01, -7.1087e-02,\n",
       "                        2.1601e-01, -7.1045e-02,  2.1140e-01,  2.6321e-01,  6.6866e-02,\n",
       "                        2.8278e-01,  2.3007e-01, -1.7826e-01, -5.6574e-02, -1.3027e-01,\n",
       "                        1.2568e-01, -2.7854e-01,  2.8706e-02, -1.2085e-01, -2.6853e-02,\n",
       "                        2.9258e-01, -3.0256e-01, -2.2196e-01, -2.0950e-01,  1.1884e-02,\n",
       "                       -1.7531e-02, -6.7390e-02,  3.0789e-01, -2.7568e-01,  3.8184e-02,\n",
       "                        3.0309e-01, -1.4507e-01, -2.0726e-01,  5.3576e-02, -2.2911e-02,\n",
       "                       -2.6689e-01,  1.5147e-01,  2.5468e-01, -2.3304e-01,  2.2166e-02,\n",
       "                        4.2462e-02, -2.9963e-01,  4.5801e-02,  2.9904e-01,  1.3890e-01,\n",
       "                       -5.5444e-02, -2.3070e-01,  2.8450e-01, -2.8899e-01,  2.9614e-01],\n",
       "                      [ 8.4337e-02,  1.1406e-01, -3.1398e-01,  2.9901e-01,  2.2031e-01,\n",
       "                        1.4399e-01, -1.0755e-01,  1.8029e-01,  4.6478e-02,  2.0483e-02,\n",
       "                       -2.1719e-01,  2.5007e-01,  1.0854e-01,  2.7972e-01, -3.0486e-01,\n",
       "                       -1.3177e-01,  4.0661e-03, -2.2144e-01, -1.8093e-01,  1.2663e-01,\n",
       "                        2.0953e-01,  2.9529e-01,  2.5899e-02, -1.3966e-01, -3.6302e-02,\n",
       "                       -2.4044e-01,  1.2139e-01, -1.6942e-01,  2.2905e-01, -1.5805e-01,\n",
       "                        3.0629e-01,  1.8013e-01, -2.5789e-02,  2.2048e-01,  1.0385e-01,\n",
       "                        2.8639e-01, -2.0527e-01, -3.0194e-01, -1.9449e-01,  1.8016e-01,\n",
       "                       -1.5261e-01, -2.6442e-01,  5.2495e-02,  3.0020e-01,  2.6120e-01,\n",
       "                        1.6558e-01,  9.8799e-02,  2.5898e-01, -1.4548e-01, -9.3840e-02,\n",
       "                        5.3794e-02, -1.6357e-01, -2.5234e-01, -4.4509e-02, -2.3422e-01,\n",
       "                        1.4541e-01,  4.8872e-02,  9.2183e-02, -2.8327e-01, -1.9318e-01,\n",
       "                       -1.9917e-01,  5.4160e-02,  2.3479e-01, -1.8234e-02, -2.8908e-02,\n",
       "                        3.8904e-02,  1.8851e-01, -2.9059e-01,  2.4736e-01, -2.6703e-01,\n",
       "                        2.7971e-01,  1.8569e-01,  3.1622e-01, -2.7884e-01,  9.7474e-02,\n",
       "                        1.7899e-01, -3.0167e-01,  1.4671e-01, -3.9524e-02, -1.7816e-01,\n",
       "                        2.3631e-01,  2.3803e-01, -3.8700e-02, -2.2704e-01, -2.9925e-02,\n",
       "                       -1.4971e-01, -1.3327e-01,  1.2819e-01,  2.7309e-01, -4.0083e-02,\n",
       "                        7.5870e-03,  1.0273e-01, -1.2689e-01, -3.5007e-03, -2.8688e-01,\n",
       "                       -2.2360e-01, -1.8733e-01,  8.9841e-02, -1.8544e-01,  2.7085e-01],\n",
       "                      [ 9.8453e-03, -2.1181e-01,  1.6772e-01, -2.3394e-01, -1.8643e-01,\n",
       "                        7.6638e-02, -1.3184e-01,  1.4002e-01,  9.4711e-02,  2.5158e-01,\n",
       "                       -2.7606e-01, -2.2374e-01,  1.0863e-01, -2.0514e-01,  2.1125e-01,\n",
       "                       -2.0728e-01,  5.6248e-02, -4.5943e-02,  2.9053e-01,  9.9833e-02,\n",
       "                        2.5338e-01, -1.7195e-01, -1.1879e-02, -1.8543e-01,  2.0017e-01,\n",
       "                        5.5823e-02,  3.7572e-02,  1.0975e-01, -2.7443e-01, -2.4887e-02,\n",
       "                        6.4352e-02, -3.1051e-01, -2.6029e-01,  2.1844e-01, -9.1682e-02,\n",
       "                        1.7817e-01, -1.9666e-01,  1.3682e-01,  2.8547e-01, -2.8464e-01,\n",
       "                       -1.0209e-01, -4.5969e-02,  8.1914e-03, -1.3173e-01,  1.6354e-01,\n",
       "                        2.0338e-01, -1.7266e-01,  1.8429e-01, -8.3631e-02, -1.1054e-01,\n",
       "                       -1.8632e-01, -7.2009e-03,  1.2844e-01,  2.8172e-01,  2.8115e-01,\n",
       "                        2.2126e-01,  1.1501e-01, -5.5357e-02,  9.5455e-02, -2.0242e-01,\n",
       "                        3.5170e-02,  9.5905e-02, -1.0187e-01, -2.5326e-01,  2.5834e-01,\n",
       "                       -2.9707e-01,  2.8448e-01, -1.3353e-01, -2.1708e-01,  1.7268e-03,\n",
       "                       -1.5649e-01, -2.1037e-01, -4.8961e-02,  5.4651e-02, -2.5319e-01,\n",
       "                       -2.8898e-01,  2.0851e-01, -2.0668e-01,  6.7510e-02,  1.6926e-01,\n",
       "                       -5.9091e-02, -1.4029e-01, -3.2444e-02,  4.9003e-02,  9.6136e-03,\n",
       "                       -1.6833e-01, -2.6467e-01, -9.4145e-02, -2.5399e-01, -2.6963e-01,\n",
       "                        1.2939e-01,  1.7588e-01, -1.4115e-01, -2.9401e-01, -2.4157e-01,\n",
       "                       -1.3515e-01,  1.8277e-01, -2.7839e-02,  2.8600e-02, -2.8702e-03],\n",
       "                      [ 1.8834e-01,  3.8854e-02, -1.9618e-01, -2.8287e-01,  2.2337e-01,\n",
       "                        2.4624e-01, -2.9975e-01, -2.7903e-01,  6.5341e-02,  1.5267e-01,\n",
       "                        2.1952e-01, -2.4361e-01, -1.1397e-01,  1.0423e-01, -1.4521e-01,\n",
       "                       -5.2656e-02, -2.2514e-01,  2.9335e-01,  2.8766e-01, -2.5553e-01,\n",
       "                        6.1885e-02, -1.6301e-01,  2.6434e-01, -1.7232e-01, -1.6462e-01,\n",
       "                        2.5145e-01,  2.3399e-01, -4.7845e-02, -5.9806e-02, -1.9754e-01,\n",
       "                       -1.6568e-02,  3.1032e-02,  3.6998e-03,  6.7828e-02,  1.3780e-01,\n",
       "                        1.8021e-01,  2.6055e-01,  1.5964e-01,  3.0760e-01,  1.2342e-01,\n",
       "                       -2.1041e-01, -6.2464e-03,  3.9775e-02, -1.9705e-01,  6.6491e-02,\n",
       "                        8.7934e-03,  2.9344e-01,  1.8488e-01, -1.0138e-01,  1.5013e-01,\n",
       "                       -9.8891e-02, -2.9010e-01, -7.1390e-02, -1.4637e-01, -2.0212e-01,\n",
       "                        1.4646e-01, -1.6424e-01, -3.9725e-02, -1.3933e-01, -1.7050e-01,\n",
       "                        6.7737e-02,  2.8648e-01, -6.6580e-02,  1.5202e-02,  2.1777e-01,\n",
       "                       -1.6617e-01, -1.5897e-01,  2.4479e-01,  2.1216e-01,  1.4954e-01,\n",
       "                        3.1204e-01,  1.6980e-01,  7.4695e-02,  1.5032e-01, -2.6775e-02,\n",
       "                       -1.6900e-02, -1.2292e-01, -3.1416e-01,  1.4599e-01,  2.1231e-01,\n",
       "                        4.9794e-04,  2.9515e-01,  1.8462e-01,  2.2681e-01, -1.4036e-01,\n",
       "                       -1.6397e-01, -2.1087e-01,  3.5919e-02,  1.9530e-01,  1.5877e-01,\n",
       "                        4.1202e-03,  5.6858e-02, -2.5609e-02,  1.7497e-01, -1.0004e-01,\n",
       "                       -1.0043e-01, -6.0626e-02,  1.2827e-01, -4.9578e-02, -1.7706e-01],\n",
       "                      [ 1.1508e-01, -2.3552e-01, -1.6425e-01, -2.1378e-01,  8.5641e-02,\n",
       "                       -8.1793e-02, -1.2915e-01, -2.3381e-01,  1.5304e-01,  9.1034e-02,\n",
       "                       -7.7698e-02,  2.7449e-01, -2.8220e-02,  1.4997e-01,  1.5895e-01,\n",
       "                        2.5002e-02, -1.0786e-01, -3.1290e-01,  6.7109e-02, -2.9294e-01,\n",
       "                        1.0382e-01, -2.6316e-01,  1.3164e-04,  7.3078e-02,  2.0266e-01,\n",
       "                       -4.9903e-02,  2.8039e-01,  2.8494e-01, -4.3564e-02,  1.6217e-01,\n",
       "                        1.7695e-01, -1.7238e-01, -1.1256e-01,  1.7022e-01, -1.2544e-02,\n",
       "                        5.7898e-02,  5.7971e-02,  5.7418e-02, -2.2248e-01, -1.2920e-01,\n",
       "                        1.5883e-01,  2.0967e-01, -1.8953e-01,  5.6552e-02, -6.5261e-02,\n",
       "                        1.2348e-01, -1.7862e-01,  1.1304e-01,  9.1700e-02,  2.8145e-02,\n",
       "                       -1.7461e-01, -5.5898e-02, -3.3321e-03, -6.9993e-02, -3.0515e-01,\n",
       "                       -8.0847e-02, -1.0214e-01, -2.5387e-01,  2.6992e-01, -1.0158e-02,\n",
       "                        1.1299e-01,  1.2231e-02, -5.2071e-02, -1.9340e-01,  2.3647e-01,\n",
       "                       -2.1376e-02, -1.2618e-02, -3.6527e-02, -6.1497e-02, -2.5630e-01,\n",
       "                       -2.7762e-01,  2.7479e-01,  1.6659e-01, -1.4626e-01, -1.4319e-01,\n",
       "                       -9.0185e-02, -2.7696e-01,  2.5698e-01, -1.0057e-01,  2.5067e-01,\n",
       "                        3.0133e-01,  6.7220e-02,  2.3889e-01,  6.1591e-02, -3.5027e-02,\n",
       "                       -1.2844e-01, -2.9591e-02, -1.1689e-01, -5.9321e-02, -1.5815e-01,\n",
       "                        2.9078e-02, -3.0745e-02,  2.4821e-01, -2.1919e-01,  2.1804e-01,\n",
       "                        2.3156e-02,  2.6872e-01,  1.0707e-01, -8.4510e-02, -2.5237e-01]],\n",
       "                     requires_grad=True)),\n",
       "             ('weight_hh_l0', Parameter containing:\n",
       "              tensor([[ 1.4704e-01, -2.8846e-01,  7.2897e-02,  1.4406e-01,  2.2542e-01,\n",
       "                        3.0182e-01, -2.8374e-01,  1.8199e-01,  1.3532e-01,  2.1240e-02],\n",
       "                      [ 3.4849e-02, -6.7260e-02, -1.0213e-01, -4.2042e-02, -2.8780e-01,\n",
       "                        6.3442e-02,  1.2104e-02, -5.4969e-02,  2.7722e-01, -3.0527e-01],\n",
       "                      [ 2.8791e-01,  3.5823e-03, -2.9399e-01,  2.7941e-01, -4.8766e-02,\n",
       "                        1.9650e-01, -2.3137e-01,  1.3448e-01, -2.4314e-01, -8.2701e-02],\n",
       "                      [-2.8446e-01,  3.0252e-01, -4.8171e-02,  2.4709e-01,  2.3029e-01,\n",
       "                       -1.8736e-01, -3.0802e-01,  2.0256e-01, -8.5224e-02,  4.3507e-02],\n",
       "                      [ 1.1780e-01, -1.0214e-02,  2.0671e-01,  1.7553e-01, -2.0033e-01,\n",
       "                       -1.5642e-02,  2.7217e-01,  2.5131e-01,  2.5860e-01, -2.8576e-01],\n",
       "                      [ 3.1294e-01,  2.0161e-01,  2.7989e-01,  2.7220e-01, -5.5479e-02,\n",
       "                       -2.3876e-01,  3.0205e-01, -1.8775e-01,  1.6607e-01, -2.0607e-01],\n",
       "                      [ 2.3291e-01,  1.2580e-01, -2.8771e-01, -9.0070e-02, -2.7866e-02,\n",
       "                        9.6106e-02, -2.0045e-01, -3.9542e-02,  2.8039e-01, -1.9339e-01],\n",
       "                      [-1.9752e-02,  2.9548e-01, -2.5010e-01,  1.2609e-01,  8.7367e-02,\n",
       "                        1.3817e-01,  3.0547e-01, -1.4906e-01,  2.5525e-02,  2.2492e-01],\n",
       "                      [-1.7050e-01, -3.0345e-01, -1.8082e-01,  8.8867e-02, -3.0508e-01,\n",
       "                       -1.3945e-04, -1.3442e-01,  2.6846e-01, -8.3974e-02,  5.1431e-02],\n",
       "                      [-6.1632e-02,  2.6599e-02,  2.6960e-01, -5.9398e-02, -8.5342e-02,\n",
       "                       -1.6224e-01,  1.8656e-01, -4.7750e-02, -8.2765e-02, -2.0323e-01]],\n",
       "                     requires_grad=True)),\n",
       "             ('bias_ih_l0', Parameter containing:\n",
       "              tensor([-0.2549,  0.1064,  0.1580, -0.2170,  0.0798, -0.0021, -0.1740, -0.2226,\n",
       "                       0.1389, -0.3110], requires_grad=True)),\n",
       "             ('bias_hh_l0', Parameter containing:\n",
       "              tensor([ 0.0546,  0.0524, -0.1410, -0.0368, -0.2619,  0.0065, -0.0519, -0.2123,\n",
       "                      -0.3000,  0.2201], requires_grad=True))])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn._parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 100]), torch.Size([10, 10]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weight_ih_l0.shape, rnn.weight_hh_l0.shape\n",
    "#这里的0 就是一层上的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10]), torch.Size([10]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.bias_ih_l0.shape, rnn.bias_hh_l0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNN输入格式 (input_size, hidden_size, num_layers)\n",
    "input_size: word vector 的维度\n",
    "hidden_size: hidden state的 size\n",
    "num_layers: number of recurrent layers, default is 1\n",
    "\n",
    "### nn.RNN 的forward函数：\n",
    "\n",
    "out, h = forward( x, h0)\n",
    "这里可以直接用x作为input， 而不需要用xt\n",
    "\n",
    "x的维度： [seq len, batch, word vec] seq len: 一句话多少个词，或者一个词多少个字母, 这里的seq 就会循环的输入不同位置的词或者字母\n",
    "\n",
    "h0/h: [num of layers, batch size , hidden dim] h0不写的话会自动为0初始化\n",
    "\n",
    "out: [seq len, batch, hidden dim]\n",
    "\n",
    "### 要注意的是out是最后一层每个x时刻的输出，h是指最后一个时刻的所有的hidden所以一层的网络 h为：[1, batch, hidden dim] 但是2层就是[2, batch, hidden dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(100, 20)\n",
      "torch.Size([10, 3, 20]) torch.Size([1, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=1)\n",
    "print (rnn)\n",
    "\n",
    "x = torch.randn(10, 3, 100)\n",
    "out, h = rnn(x, torch.zeros(1,3, 20))\n",
    "print (out.shape, h.shape)\n",
    "\n",
    "## 可以理解成x输入的是一个10个字母的单词，然后我一次输入3个这样子的单词， 每个字母用100维的向量表示\n",
    "## 可以理解成x输入的是一个10个单词的句子，然后我一次输入3个这样子的句子， 每个词用100维的向量表示"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层RNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "out: [seq len, batch, hidden dim] 不会变，因为out是最后一层\n",
    "h: [num of layers, batch size , hidden dim]  是指最后一个时刻的所有的hidden，所以两层的model就有两层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(100, 20, num_layers=4)\n",
      "torch.Size([10, 3, 20]) torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "##维度验证\n",
    "rnn = nn.RNN(input_size=100, hidden_size=20, num_layers=4)\n",
    "print (rnn)\n",
    "x = torch.randn(10, 3, 100)\n",
    "out, h = rnn(x, torch.zeros(4,3, 20))\n",
    "print (out.shape, h.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.RNNCell()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.RNNCell 输入格式 (input_size, hidden_size) 和nn.RNN的前两个一致，但是没有num_layers\n",
    "RNNcell就相当于是一个个字母、词往 model里面送，而不是一次从头送到尾\n",
    "\n",
    "### nn.RNNCell 的forward函数(不一样了）：\n",
    "每次送3句话中t时刻的那个单词\n",
    "\n",
    "ht = rnnCell(xt, ht_1)  \n",
    "xt: [batch, word vect] <br>\n",
    "ht_1/ ht: [number of layers, batch, h dim] 没有变 <br> \n",
    "out = torch.stack ([h1, h2, ..., ht]) out是所有hidden 状态的集合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell1 = nn.RNNCell(100, 20)\n",
    "h1 = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)\n",
    "#需要人为的loop\n",
    "print (h1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层RNNCell例子，因为层要自己stack 所以就没有num_layers 这个参数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell1 = nn.RNNCell(100, 30)\n",
    "cell2 = nn.RNNCell(30, 20)\n",
    "#100 个词的句子，先变成30 的memory 然后30 的memory 往下传最后输出20维\n",
    "#30 30 必须匹配\n",
    "h1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 20)\n",
    "for xt in x:\n",
    "    h1 = cell1(xt, h1)\n",
    "    h2 = cell2(h1, h2)\n",
    "    \n",
    "print (h2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 波形预测示例： 预测下一个点\n",
    "https://www.udemy.com/course/deeplearning-pytorch/learn/lecture/14400076#announcements\n",
    "\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials/blob/master/lesson49-时间序列预测/seris.py\n",
    "\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials/blob/master/lesson49-时间序列预测/49.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 loss 0.6126097440719604\n",
      "Iteration: 100 loss 0.006553624290972948\n",
      "Iteration: 200 loss 0.0036741343792527914\n",
      "Iteration: 300 loss 0.004274554550647736\n",
      "Iteration: 400 loss 0.001386076444759965\n",
      "Iteration: 500 loss 0.0009297072538174689\n",
      "Iteration: 600 loss 0.0010618617525324225\n",
      "Iteration: 700 loss 0.0047167143784463406\n",
      "Iteration: 800 loss 0.0015864659799262881\n",
      "Iteration: 900 loss 0.004065653309226036\n",
      "Iteration: 1000 loss 0.0006874892278574407\n",
      "Iteration: 1100 loss 0.0005984943709336221\n",
      "Iteration: 1200 loss 0.0017141381977126002\n",
      "Iteration: 1300 loss 0.0008544972515664995\n",
      "Iteration: 1400 loss 0.0016634584171697497\n",
      "Iteration: 1500 loss 0.0003238616627641022\n",
      "Iteration: 1600 loss 0.00029018279747106135\n",
      "Iteration: 1700 loss 0.0005660462775267661\n",
      "Iteration: 1800 loss 0.0003452846722211689\n",
      "Iteration: 1900 loss 0.0005758561892434955\n",
      "Iteration: 2000 loss 0.0007382043404504657\n",
      "Iteration: 2100 loss 0.0003907473001163453\n",
      "Iteration: 2200 loss 0.00036268256371840835\n",
      "Iteration: 2300 loss 0.0006660543149337173\n",
      "Iteration: 2400 loss 0.00014417611237149686\n",
      "Iteration: 2500 loss 0.0004970271838828921\n",
      "Iteration: 2600 loss 0.0018135207938030362\n",
      "Iteration: 2700 loss 0.00024364583077840507\n",
      "Iteration: 2800 loss 0.0005954382359050214\n",
      "Iteration: 2900 loss 0.0003798316465690732\n",
      "Iteration: 3000 loss 0.00018520605226512998\n",
      "Iteration: 3100 loss 6.743878475390375e-05\n",
      "Iteration: 3200 loss 0.00025832708342932165\n",
      "Iteration: 3300 loss 0.0003913886903319508\n",
      "Iteration: 3400 loss 9.119451715378091e-05\n",
      "Iteration: 3500 loss 0.000514641753397882\n",
      "Iteration: 3600 loss 0.00029128362075425684\n",
      "Iteration: 3700 loss 0.0001477447513025254\n",
      "Iteration: 3800 loss 0.00012391811469569802\n",
      "Iteration: 3900 loss 0.00033604822237975895\n",
      "Iteration: 4000 loss 0.0003422847657930106\n",
      "Iteration: 4100 loss 0.00014775604358874261\n",
      "Iteration: 4200 loss 0.00021874194499105215\n",
      "Iteration: 4300 loss 0.00033196606091223657\n",
      "Iteration: 4400 loss 0.0009534072014503181\n",
      "Iteration: 4500 loss 0.0006157880998216569\n",
      "Iteration: 4600 loss 0.0003593612927943468\n",
      "Iteration: 4700 loss 0.00024869153276085854\n",
      "Iteration: 4800 loss 0.0005959723494015634\n",
      "Iteration: 4900 loss 7.373589323833585e-05\n",
      "Iteration: 5000 loss 0.0003391407954040915\n",
      "Iteration: 5100 loss 0.0005821248632855713\n",
      "Iteration: 5200 loss 0.0003330366453155875\n",
      "Iteration: 5300 loss 0.0003503288025967777\n",
      "Iteration: 5400 loss 0.00019669845642056316\n",
      "Iteration: 5500 loss 0.0002986079198308289\n",
      "Iteration: 5600 loss 0.0005877974908798933\n",
      "Iteration: 5700 loss 0.00018613674910739064\n",
      "Iteration: 5800 loss 0.0005459332023747265\n",
      "Iteration: 5900 loss 0.00022830965463072062\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import  numpy as np\n",
    "import  torch\n",
    "import  torch.nn as nn\n",
    "import  torch.optim as optim\n",
    "from    matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "num_time_steps = 50\n",
    "input_size = 1\n",
    "hidden_size = 16\n",
    "output_size = 1\n",
    "lr=0.01\n",
    "\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self, ):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.rnn = nn.RNN(\n",
    "            input_size=input_size,\n",
    "            ##一个数字，1 \n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "            ##[b, seq, feature维度] 这种表达方式\n",
    "        )\n",
    "        for p in self.rnn.parameters():\n",
    "            nn.init.normal_(p, mean=0.0, std=0.001)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, hidden_prev):\n",
    "        out, hidden_prev = self.rnn(x, hidden_prev)\n",
    "        # out： [b, seq, h] hidden_prev: [batch, numer of layer=1, hidden]\n",
    "        # [b=1, seq, h] 打平成 [seq, h]\n",
    "        # view is for reshap: parameter -1 you don't know the number of rows so use -1, you want hidden of columns\n",
    "        out = out.view(-1, hidden_size)\n",
    "        out = self.linear(out) \n",
    "        #[seq, h ] -> [seq, 1]\n",
    "        out = out.unsqueeze(dim=0)\n",
    "        #插入一个维度： [seq, 1] -》 [1, seq, 1] 因为要和y 进行比较，y的维度是[b, seq, 1]\n",
    "        # unsqueeze() inserts singleton dim at position given as parameter and view() creates a view with different dimensions of the storage associated with tensor.\n",
    "        # we need to calculate mse between out and y\n",
    "        return out, hidden_prev\n",
    "\n",
    "\n",
    "### train the model\n",
    "\n",
    "model = Net()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr)\n",
    "\n",
    "hidden_prev = torch.zeros(1, 1, hidden_size)\n",
    "\n",
    "for iter in range(6000):\n",
    "    start = np.random.randint(3, size=1)[0]\n",
    "    time_steps = np.linspace(start, start + 10, num_time_steps)\n",
    "    data = np.sin(time_steps)\n",
    "    data = data.reshape(num_time_steps, 1)\n",
    "    x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)\n",
    "    y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)\n",
    "\n",
    "    output, hidden_prev = model(x, hidden_prev)\n",
    "    hidden_prev = hidden_prev.detach()\n",
    "\n",
    "    loss = criterion(output, y)\n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    # for p in model.parameters():\n",
    "    #     print(p.grad.norm())\n",
    "    # torch.nn.utils.clip_grad_norm_(p, 10)\n",
    "    optimizer.step()\n",
    "\n",
    "    if iter % 100 == 0:\n",
    "        print(\"Iteration: {} loss {}\".format(iter, loss.item()))\n",
    "\n",
    "## 每次喂50个点 sequence，batch sample size、obs为1，  每个点用一个数字表示 worddim =1\n",
    "## 这个例子用[batch=1， 50， 1]  start 点0-3间随机取，反正每过50个点的波形一样\n",
    "#data 就是产生的training数据，我们希望给你0-49的数据你可以预测 1-50 的数据\n",
    "#比较难的是给你0-40的数据你可以预测 10-50 的数据\n",
    "start = np.random.randint(3, size=1)[0]\n",
    "time_steps = np.linspace(start, start + 10, num_time_steps)\n",
    "data = np.sin(time_steps)\n",
    "data = data.reshape(num_time_steps, 1)\n",
    "x = torch.tensor(data[:-1]).float().view(1, num_time_steps - 1, 1)\n",
    "y = torch.tensor(data[1:]).float().view(1, num_time_steps - 1, 1)\n",
    "\n",
    "\n",
    "#prediction and test\n",
    "predictions = []\n",
    "input = x[:, 0, :] ## 保留的是[b,1]\n",
    "for _ in range(x.shape[1]):\n",
    "    input = input.view(1, 1, 1)\n",
    "    (pred, hidden_prev) = model(input, hidden_prev)\n",
    "    input = pred #一个一个往里面送\n",
    "    predictions.append(pred.detach().numpy().ravel()[0])\n",
    "\n",
    "x = x.data.numpy().ravel()\n",
    "y = y.data.numpy()\n",
    "plt.scatter(time_steps[:-1], x.ravel(), s=90)\n",
    "plt.plot(time_steps[:-1], x.ravel())\n",
    "\n",
    "plt.scatter(time_steps[1:], predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN训练难题\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorch-Tutorials/tree/master/lesson50-RNN训练难题\n",
    "\n",
    "Gradient exploding \n",
    "\n",
    "Gradient vanishing\n",
    "\n",
    "how to solve: Gradient clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(output, y)\n",
    "mode.zero_grad()\n",
    "loss.backward()\n",
    "for p in model.parameters():\n",
    "    print (p.grad.norm())\n",
    "    torch.nn.utils.clip_grad_norm_(p,10)\n",
    "optimizer.step()\n",
    "## 一般loss 在10以内比较好\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM原理\n",
    "RNN： short term memory\n",
    "\n",
    "LSTM： long short term dependency\n",
    "\n",
    "\n",
    "三道门控制1)过去的信息，2)新的输入，3)输出， 用sigmoid() 控制输出的量\n",
    "Forget gate： 1 全部记住，0 全部忘记: ft = sigmoid (Wf* [ht-1, xt] +bf) 上一个时间点的h和现在时间点的x\n",
    "\n",
    "input gate： sigmoid( Wi *[ht-1, xt] + bi)  decide 门的开度\n",
    "Ct~ = tanh（Wc*[ht-1,xt] +bc) 新进去的信息并不仅仅是xt 而是要与前面的ht-融合的。\n",
    "然后将forget gate 施加在Ct-1 将input gate 输入们施加在Ct上\n",
    "Ct=ft*Ct-1 + it*Ct~ （这个Ct 其实就是RNN里面的ht）\n",
    "\n",
    "output gate：Ct-> ht (这里的ht是输出了)\n",
    "ht=Ot* tanh(Ct)\n",
    "\n",
    "因为LSTM使用累加（用们的开度）而不是次方的形式，所以可以有效的减少Gradient vanishing。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTM model输入格式 (input_size, hidden_size, num_layers)  和RNN是一样的\n",
    "\n",
    "### nn.LSTMforward 函数\n",
    "out, (ht, ct) = lstm( x, [ht0, ct0])\n",
    "\n",
    "out是所有时间戳上最后一层的ht的状态\n",
    "ht，ct 是最后一个时间戳的h和c的状态\n",
    "x:[ seq length, batch, word vec dim]\n",
    "h/c: [number of layer, batch size, hidden size]\n",
    "out:[seq length, batch, hidden size]\n",
    "\n",
    "所以比较RNN， 唯一的变化是 原来的 h 变成了一个tuple （ht，ct）\n",
    "\n",
    "RNN forward 函数是：out, h = forward( x, h0) 这里可以直接用x作为input， 而不需要用xt\n",
    "x的维度： [seq len, batch, word vec] seq len: 一句话多少个词，或者一个词多少个字母, 这里的seq 就会循环的输入不同位置的词或者字母\n",
    "h0/h: [num of layers, batch size , hidden dim] h0不写的话会自动为0初始化\n",
    "out: [seq len, batch, hidden dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM(100, 20, num_layers=4)\n",
      "torch.Size([10, 3, 100]) torch.Size([10, 3, 20]) torch.Size([4, 3, 20]) torch.Size([4, 3, 20])\n"
     ]
    }
   ],
   "source": [
    "##LSTM dim examples\n",
    "lstm = nn.LSTM(input_size=100, hidden_size=20, num_layers=4)\n",
    "print (lstm)\n",
    "\n",
    "x = torch.randn(10, 3, 100)\n",
    "out, (h, c) = lstm(x)\n",
    "print (x.shape, out.shape, h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "?nn.LSTM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.LSTMCell model输入格式 (input_size, hidden_size, num_layers) 和 nn.LSTM是一样的\n",
    "\n",
    "### nn.LSTMCell forward 函数\n",
    "ht, ct = lstmcell(xt, [ht_1, ct_1])\n",
    "xt : [b, vec]\n",
    "ht/ct: [b, h]\n",
    "\n",
    "\n",
    "\n",
    "比较：RNNCell\n",
    "ht = rnnCell(xt, ht_1)\n",
    "xt: [batch, word vect] \n",
    "ht_1/ ht: [number of layers, batch, h dim] 没有变 \n",
    "**out = torch.stack ([h1, h2, ..., ht]) out是所有hidden 状态的集合\n",
    "\n",
    "最后的输出可以是所有h的集合，也可以是最后一个状态的h，这个可以自己定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20]) torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell=nn.LSTMCell(input_size=100, hidden_size=20)\n",
    "h = torch.zeros(3, 20)\n",
    "c = torch.zeros(3, 20)\n",
    "\n",
    "for xt in x:\n",
    "    h, c = cell(xt, [h, c])\n",
    "print (h.shape, c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层LSTMCell例子，因为层要自己stack 所以就没有num_layers 这个参数了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20]) torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "cell1 = nn.LSTMCell(100, 30)\n",
    "cell2 = nn.LSTMCell(30, 20)\n",
    "#100 个词的句子，先变成30 的memory 然后30 的memory 往下传最后输出20维\n",
    "#30 30 必须匹配\n",
    "h1 = torch.zeros(3, 30)\n",
    "c1 = torch.zeros(3, 30)\n",
    "h2 = torch.zeros(3, 20)\n",
    "c2 = torch.zeros(3, 20)\n",
    "\n",
    "for xt in x:\n",
    "    h1, c1 = cell1(xt, [h1, c1])\n",
    "    h2, c2 = cell2(h1, [h2, c2])\n",
    "    \n",
    "print (h2.shape, c2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 情感分类实战 Sentiment Classification\n",
    "https://github.com/dragen1860/Deep-Learning-with-PyTorchTutorials/tree/master/lesson53-情感分类实战\n",
    "\n",
    "https://www.udemy.com/course/deeplearningpytorch/learn/lecture/14400112#announcements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***用所有的h的集合sum来做做最后的output然后 通过线性分类器来做出最后的binary结果\n",
    "\n",
    "***用Glove的embedding来表示所有的词和句子\n",
    "\n",
    "*** Google Colab <br>\n",
    "free K80 for GPU， Continuous 12 hours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"lstm\n",
    "Automatically generated by Colaboratory.\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1GX0Rqur8T45MSYhLU9MYWAbycfLH4-Fu\n",
    "\"\"\"\n",
    "\n",
    "!pip install torch\n",
    "!pip install torchtext\n",
    "!python -m spacy download en\n",
    "\n",
    "\n",
    "# K80 gpu for 12 hours\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torchtext import data, datasets\n",
    "\n",
    "print('GPU:', torch.cuda.is_available())\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "TEXT = data.Field(tokenize='spacy')\n",
    "LABEL = data.LabelField(dtype=torch.float)\n",
    "train_data, test_data = datasets.IMDB.splits(TEXT, LABEL)\n",
    "\n",
    "print('len of train data:', len(train_data))\n",
    "print('len of test data:', len(test_data))\n",
    "\n",
    "print(train_data.examples[15].text)\n",
    "print(train_data.examples[15].label)\n",
    "\n",
    "# word2vec, glove\n",
    "TEXT.build_vocab(train_data, max_size=10000, vectors='glove.6B.100d')\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "\n",
    "batchsz = 30\n",
    "device = torch.device('cuda')\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data),\n",
    "    batch_size = batchsz,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # [0-10001] => [100]\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # [100] => [256]\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, \n",
    "                           bidirectional=True, dropout=0.5)\n",
    "        # [256*2] => [1]\n",
    "        self.fc = nn.Linear(hidden_dim*2, 1)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [seq_len, b] vs [b, 3, 28, 28]\n",
    "        \"\"\"\n",
    "        # [seq, b, 1] => [seq, b, 100]\n",
    "        embedding = self.dropout(self.embedding(x))\n",
    "        \n",
    "        # output: [seq, b, hid_dim*2]\n",
    "        # hidden/h: [num_layers*2, b, hid_dim]\n",
    "        # cell/c: [num_layers*2, b, hid_di]\n",
    "        output, (hidden, cell) = self.rnn(embedding)\n",
    "        #because it bidirectional so you need to *2\n",
    "        \n",
    "        # [num_layers*2, b, hid_dim] => 2 of [b, hid_dim] => [b, hid_dim*2]\n",
    "        hidden = torch.cat([hidden[-2], hidden[-1]], dim=1)\n",
    "        \n",
    "        # [b, hid_dim*2] => [b, 1]\n",
    "        hidden = self.dropout(hidden)\n",
    "        # use fully connected layer to make the result one dimension\n",
    "        out = self.fc(hidden)\n",
    "        \n",
    "        return out\n",
    "\n",
    "rnn = RNN(len(TEXT.vocab), 100, 256)\n",
    "\n",
    "pretrained_embedding = TEXT.vocab.vectors\n",
    "print('pretrained_embedding:', pretrained_embedding.shape)\n",
    "rnn.embedding.weight.data.copy_(pretrained_embedding)\n",
    "print('embedding layer inited.')\n",
    "\n",
    "#TEXT is the glove data\n",
    "\n",
    "\n",
    "optimizer = optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "criteon = nn.BCEWithLogitsLoss().to(device)\n",
    "rnn.to(device)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def binary_acc(preds, y):\n",
    "    \"\"\"\n",
    "    get accuracy\n",
    "    \"\"\"\n",
    "    preds = torch.round(torch.sigmoid(preds))\n",
    "    correct = torch.eq(preds, y).float()\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "def train(rnn, iterator, optimizer, criteon):\n",
    "    \n",
    "    avg_acc = []\n",
    "    rnn.train()\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        \n",
    "        # [seq, b] => [b, 1] => [b]\n",
    "        pred = rnn(batch.text).squeeze(1)\n",
    "        # \n",
    "        loss = criteon(pred, batch.label)\n",
    "        acc = binary_acc(pred, batch.label).item()\n",
    "        avg_acc.append(acc)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%10 == 0:\n",
    "            print(i, acc)\n",
    "        \n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    print('avg acc:', avg_acc)\n",
    "    \n",
    "    \n",
    "def eval(rnn, iterator, criteon):\n",
    "    \n",
    "    avg_acc = []\n",
    "    \n",
    "    rnn.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "\n",
    "            # [b, 1] => [b]\n",
    "            pred = rnn(batch.text).squeeze(1)\n",
    "\n",
    "            #\n",
    "            loss = criteon(pred, batch.label)\n",
    "\n",
    "            acc = binary_acc(pred, batch.label).item()\n",
    "            avg_acc.append(acc)\n",
    "        \n",
    "    avg_acc = np.array(avg_acc).mean()\n",
    "    \n",
    "    print('>>test:', avg_acc)\n",
    "\n",
    "for epoch in range(10):\n",
    "    \n",
    "    eval(rnn, test_iterator, criteon)\n",
    "    train(rnn, train_iterator, optimizer, criteon)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
